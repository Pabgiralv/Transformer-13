{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:33.953470Z","iopub.execute_input":"2022-06-18T16:38:33.953887Z","iopub.status.idle":"2022-06-18T16:38:35.788326Z","shell.execute_reply.started":"2022-06-18T16:38:33.953816Z","shell.execute_reply":"2022-06-18T16:38:35.787185Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torchvision\nimport torch\nimport torchvision.transforms as transforms\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn as nn\nimport math\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:35.790280Z","iopub.execute_input":"2022-06-18T16:38:35.790829Z","iopub.status.idle":"2022-06-18T16:38:36.137781Z","shell.execute_reply.started":"2022-06-18T16:38:35.790793Z","shell.execute_reply":"2022-06-18T16:38:36.136875Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dataset_path = '../input/pajaros/birds/birds'\n\ntrain_transforms = transforms.Compose ([\n    transforms.Resize((32,32)),\n    transforms.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:36.138849Z","iopub.execute_input":"2022-06-18T16:38:36.139511Z","iopub.status.idle":"2022-06-18T16:38:36.148828Z","shell.execute_reply.started":"2022-06-18T16:38:36.139467Z","shell.execute_reply":"2022-06-18T16:38:36.148143Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dataset = torchvision.datasets.ImageFolder(root = train_dataset_path, transform = train_transforms)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:36.150733Z","iopub.execute_input":"2022-06-18T16:38:36.151390Z","iopub.status.idle":"2022-06-18T16:38:44.718474Z","shell.execute_reply.started":"2022-06-18T16:38:36.151356Z","shell.execute_reply":"2022-06-18T16:38:44.717442Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def show_transformed_images(dataset):\n    loader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True)\n    batch = next(iter(loader))\n    images, labels = batch\n\n    grid = torchvision.utils.make_grid(images, nrow = 3)\n    plt.figure(figsize=(11,11))\n    plt.imshow(np.transpose(grid, (1,2,0)))\n    print('labels: ', labels)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:44.719614Z","iopub.execute_input":"2022-06-18T16:38:44.720538Z","iopub.status.idle":"2022-06-18T16:38:44.726508Z","shell.execute_reply.started":"2022-06-18T16:38:44.720506Z","shell.execute_reply":"2022-06-18T16:38:44.725583Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"show_transformed_images(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:44.727799Z","iopub.execute_input":"2022-06-18T16:38:44.728308Z","iopub.status.idle":"2022-06-18T16:38:45.149814Z","shell.execute_reply.started":"2022-06-18T16:38:44.728272Z","shell.execute_reply":"2022-06-18T16:38:45.148939Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class PatchEmbedding(nn.Module):\n    def __init__(self, img_size, patch_size, in_chans, embed_dim):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.n_patches = (img_size // patch_size) ** 2\n        self.patch_size = patch_size\n        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n\n    def forward(self, x):\n        x = self.proj(x)  # (B, E, P, P)\n        x = x.flatten(2)  # (B, E, N)\n        x = x.transpose(1, 2)  # (B, N, E)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:45.150794Z","iopub.execute_input":"2022-06-18T16:38:45.151153Z","iopub.status.idle":"2022-06-18T16:38:45.158784Z","shell.execute_reply.started":"2022-06-18T16:38:45.151117Z","shell.execute_reply":"2022-06-18T16:38:45.158055Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle=True)\nbatch = next(iter(loader))\nimages, labels = batch\npe = PatchEmbedding(32, 16, 3, 600)\nout = pe(images)\nout.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:45.159902Z","iopub.execute_input":"2022-06-18T16:38:45.160755Z","iopub.status.idle":"2022-06-18T16:38:45.359776Z","shell.execute_reply.started":"2022-06-18T16:38:45.160705Z","shell.execute_reply":"2022-06-18T16:38:45.358989Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n\n    def __init__(self, n_embd, n_heads):\n        super().__init__()\n        self.n_heads = n_heads\n\n        # key, query, value projections\n        self.key = nn.Linear(n_embd, n_embd*n_heads)\n        self.query = nn.Linear(n_embd, n_embd*n_heads)\n        self.value = nn.Linear(n_embd, n_embd*n_heads)\n\n        # output projection\n        self.proj = nn.Linear(n_embd*n_heads, n_embd)\n\n    def forward(self, x):\n        B, L, F = x.size()\n\n        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n        k = self.key(x).view(B, L, F, self.n_heads).transpose(1, 3) # (B, nh, L, F)\n        q = self.query(x).view(B, L, F, self.n_heads).transpose(1, 3) # (B, nh, L, F)\n        v = self.value(x).view(B, L, F, self.n_heads).transpose(1, 3) # (B, nh, L, F)\n\n        # attention (B, nh, L, F) x (B, nh, F, L) -> (B, nh, L, L)\n        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        att = torch.nn.functional.softmax(att, dim=-1)\n        y = att @ v # (B, nh, L, L) x (B, nh, L, F) -> (B, nh, L, F)\n        y = y.transpose(1, 2).contiguous().view(B, L, F*self.n_heads) # re-assemble all head outputs side by side\n\n        return self.proj(y)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:45.361044Z","iopub.execute_input":"2022-06-18T16:38:45.361511Z","iopub.status.idle":"2022-06-18T16:38:45.373413Z","shell.execute_reply.started":"2022-06-18T16:38:45.361468Z","shell.execute_reply":"2022-06-18T16:38:45.372310Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, n_embd, n_heads):\n        super().__init__()\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n        self.attn = MultiHeadAttention(n_embd, n_heads)\n        self.mlp = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd),\n            nn.ReLU(),\n            nn.Linear(4 * n_embd, n_embd),\n        )\n\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))\n        x = x + self.mlp(self.ln2(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:45.377638Z","iopub.execute_input":"2022-06-18T16:38:45.378348Z","iopub.status.idle":"2022-06-18T16:38:45.388465Z","shell.execute_reply.started":"2022-06-18T16:38:45.378251Z","shell.execute_reply":"2022-06-18T16:38:45.387555Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class ViT(nn.Module):\n\n    def __init__(self, img_size=32, patch_size=16, in_chans=3, embed_dim=600, n_heads=10, n_layers=5, n_classes=400):\n        super().__init__()\n\n        self.patch_embed = PatchEmbedding(img_size, patch_size, in_chans, embed_dim)\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n        self.pos_embed = nn.Parameter(torch.zeros(1, 1+ self.patch_embed.n_patches, embed_dim))\n        \n        self.tranformer = torch.nn.Sequential(*[TransformerBlock(embed_dim, n_heads) for _ in range(n_layers)])\n        \n        self.ln = nn.LayerNorm(embed_dim)\n        self.fc = torch.nn.Linear(embed_dim, n_classes)\n\n    def forward(self, x):\n        e = self.patch_embed(x)\n        B, L, E = e.size()\n        \n        cls_token = self.cls_token.expand(B, -1, -1)  # (B, 1, E)\n        e = torch.cat((cls_token, e), dim=1)  # (B, 1 + N, E)\n        e = e + self.pos_embed  # (B, 1 + N, E)\n        \n        z = self.tranformer(e)\n        \n        cls_token_final = z[:, 0]  \n        y = self.fc(cls_token_final)\n\n        return y\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:45.390198Z","iopub.execute_input":"2022-06-18T16:38:45.390766Z","iopub.status.idle":"2022-06-18T16:38:45.403865Z","shell.execute_reply.started":"2022-06-18T16:38:45.390723Z","shell.execute_reply":"2022-06-18T16:38:45.403003Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"vit = ViT()\nout = vit(images)\nout.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:45.406415Z","iopub.execute_input":"2022-06-18T16:38:45.406893Z","iopub.status.idle":"2022-06-18T16:38:52.385716Z","shell.execute_reply.started":"2022-06-18T16:38:45.406853Z","shell.execute_reply":"2022-06-18T16:38:52.384932Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import pytorch_lightning as pl","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:52.386921Z","iopub.execute_input":"2022-06-18T16:38:52.387762Z","iopub.status.idle":"2022-06-18T16:38:57.283545Z","shell.execute_reply.started":"2022-06-18T16:38:52.387725Z","shell.execute_reply":"2022-06-18T16:38:57.282687Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Model(pl.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        self.vit = ViT()\n\n    def forward(self, x):\n        return self.vit(x)\n\n    def predict(self, x):\n        with torch.no_grad():\n            y_hat = self(x)    \n            return torch.argmax(y_hat, axis=1)\n        \n    def compute_loss_and_acc(self, batch):\n        x, y = batch\n        y_hat = self(x)\n        loss = F.cross_entropy(y_hat, y)\n        acc = (torch.argmax(y_hat, axis=1) == y).sum().item() / y.shape[0]\n        return loss, acc\n    \n    def training_step(self, batch, batch_idx):\n        loss, acc = self.compute_loss_and_acc(batch)\n        self.log('loss', loss)\n        self.log('acc', acc, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss, acc = self.compute_loss_and_acc(batch)\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', acc, prog_bar=True)\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=0.0003)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:57.285024Z","iopub.execute_input":"2022-06-18T16:38:57.285928Z","iopub.status.idle":"2022-06-18T16:38:57.297650Z","shell.execute_reply.started":"2022-06-18T16:38:57.285889Z","shell.execute_reply":"2022-06-18T16:38:57.296518Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = Model()\nout = model(images)\nout.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:38:57.298848Z","iopub.execute_input":"2022-06-18T16:38:57.299316Z","iopub.status.idle":"2022-06-18T16:39:04.440723Z","shell.execute_reply.started":"2022-06-18T16:38:57.299281Z","shell.execute_reply":"2022-06-18T16:39:04.439766Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = Model()\ntrainer = pl.Trainer(max_epochs=5, gpus=1, logger=None)\ntrainer.fit(model, loader)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T16:39:04.442369Z","iopub.execute_input":"2022-06-18T16:39:04.442800Z","iopub.status.idle":"2022-06-18T17:18:48.859016Z","shell.execute_reply.started":"2022-06-18T16:39:04.442764Z","shell.execute_reply":"2022-06-18T17:18:48.858230Z"},"trusted":true},"execution_count":16,"outputs":[]}]}